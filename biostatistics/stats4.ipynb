{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0599a8cf",
   "metadata": {},
   "source": [
    "# Nonparametric testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8516976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statistics\n",
    "import os \n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from numpy.random import randn\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e5f15",
   "metadata": {},
   "source": [
    "## Comparing parametric and non-parametric testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e186e",
   "metadata": {},
   "source": [
    "To compare parametric and non-parametric testing, lets go back to the example counting white blood cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('https://raw.githubusercontent.com/BiAPoL/Bio-image_Analysis_with_Python/main/biostatistics/data/leukocyte_counts.csv')\n",
    "\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33208498",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(data=dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cce049",
   "metadata": {},
   "source": [
    "Now to compare healthy with COVID19 we are doing a t-test that compares the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(dat['healthy'],dat['COVID19'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58f5e8",
   "metadata": {},
   "source": [
    "The assumption of equal standard deviation was however violated for this test, so maybe we should have taken a non-parametric test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2decc1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.wilcoxon(dat['healthy'],dat['COVID19'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10d86d",
   "metadata": {},
   "source": [
    "How about the difference healthy-CLL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf97687",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(dat['healthy'],dat['CLL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.wilcoxon(dat['healthy'],dat['CLL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbff64",
   "metadata": {},
   "source": [
    "Our p-value is one order of magnitude larger. Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b735e825",
   "metadata": {},
   "source": [
    "Wilcoxon is comparing the ranks, so some information is lost, which frequently leads to loss of power. What is actually compared? Lets take the ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = st.rankdata(dat[['healthy','CLL']]).reshape(100,2)\n",
    "\n",
    "sns.swarmplot(data=df4)\n",
    "plt.ylabel(\"ranks\")\n",
    "\n",
    "df2 = pd.DataFrame(df4)\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5d5e547",
   "metadata": {},
   "source": [
    "Here we can directly see that extreme values are put in their place. For a t-test these have a high influence for the outcome and therefore increase power - and vulnerability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2f678",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef41893",
   "metadata": {},
   "source": [
    "Now we have three samples, so a t-test is actually not appropriate. If we state the 0-Hypothesis that there is no difference between samples, we should apply a one-way ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a215ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(data=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb667d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.f_oneway(dat['healthy'],dat['COVID19'],dat['CLL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add78e3",
   "metadata": {},
   "source": [
    "Now we know that we can reject H0 that there is no difference between the means in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83158f70",
   "metadata": {},
   "source": [
    "How does this look for a non-parametric situation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c80e2",
   "metadata": {},
   "source": [
    "## Comparing Kruskal-Wallis with ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = st.rankdata(dat).reshape(100,3)\n",
    "\n",
    "sns.swarmplot(data=df4)\n",
    "plt.ylabel(\"ranks\")\n",
    "\n",
    "df2 = pd.DataFrame(df4)\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.kruskal(dat['healthy'],dat['COVID19'],dat['CLL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65ec03",
   "metadata": {},
   "source": [
    "As before, we are loosing a bit of power. From the ranking plot, it becomes especially clear that we are looking at all comparisons at the same time.... but we really want to know which one makes the difference! But here we need to include Multiple testing correction!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb9f171",
   "metadata": {},
   "source": [
    "## Multiple testing correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5794e1",
   "metadata": {},
   "source": [
    "For ANOVA there is Tukey. For non-parametric tests, there is Dunn's test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5511d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Tukey the dataframe needs to be melted\n",
    "melted = pd.melt(dat)\n",
    "print(melted)\n",
    "\n",
    "# perform multiple pairwise comparison (Tukey HSD)\n",
    "m_comp = pairwise_tukeyhsd(endog=melted['value'], groups=melted['variable'], alpha=0.05)\n",
    "print(m_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16305f",
   "metadata": {},
   "source": [
    "Also in these tests the individual comparisons are not independent, which makes them very suitable for moderately multiple testing correction.  \n",
    "When going \"big\", Bonferroni and Benjamini-Hochberg are more custom, which for the former just correct by the total numbers of comparisons and for the latter adjust the false discovery rate (FDR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20421385",
   "metadata": {},
   "source": [
    "## Correlation statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb1a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Because I am lagging the creativity at the moment to make good relatable data, lets simulate some randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 20 * randn(1000) + 100\n",
    "s2 = s1+ (10 * randn(1000) + 50)\n",
    "s3 = s2+ (10 * randn(1000) + 50)\n",
    "s4 = s3+ (10 * randn(1000) + 50)\n",
    "\n",
    "plt.hist(s1,alpha=0.5)\n",
    "plt.hist(s2,alpha=0.5)\n",
    "plt.hist(s3,alpha=0.5)\n",
    "plt.hist(s4,alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"value\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.axvline(statistics.mean(s1), color=\"blue\")\n",
    "plt.axvline(statistics.mean(s2), color=\"red\")\n",
    "plt.axvline(statistics.mean(s3), color=\"green\")\n",
    "plt.axvline(statistics.mean(s4), color=\"purple\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c845fa",
   "metadata": {},
   "source": [
    "This plot shows us that they are reasonably normally distributed.  \n",
    "These data are now matched - information we are loosing with this visualisation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1903976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'s1':s1, 's2':s2})\n",
    "sns.scatterplot(x=df['s1'],y=df['s2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7879c76",
   "metadata": {},
   "source": [
    "And with a regression line + confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb17365",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df['s1'],y=df['s2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a8922",
   "metadata": {},
   "source": [
    "Because we can assume normal distribution for each of the dimensions separately, Pearson correlation is an appropriate correlation statistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.pearsonr(x=df['s1'],y=df['s2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55622f61",
   "metadata": {},
   "source": [
    "Although here we do not have to use non-parametric statistics, lets have a look how it perfroms with Spearman."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac96706",
   "metadata": {},
   "source": [
    "How do the data look like, if we consider ranks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d96a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = st.rankdata(df[['s1','s2']]).reshape(1000,2)\n",
    "df4 = pd.DataFrame(df4)\n",
    "sns.scatterplot(x=df4[0],y=df4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac45e0",
   "metadata": {},
   "source": [
    "Here you can already see that the ranks do not look random...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c161bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.spearmanr(a=df['s1'],b=df['s2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4aeac",
   "metadata": {},
   "source": [
    "What to do with multiple dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'s1':s1, 's2':s2,'s3':s3, 's4':s4})\n",
    "px.scatter_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb2ac5",
   "metadata": {},
   "source": [
    "Exercise: How do these samples relate to each other? Can you use the correlation as a measure to group them and visualise their relationship in a heatmap for example?  \n",
    "How does the correlation relate to whether the distributions are different? How are they connected?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
